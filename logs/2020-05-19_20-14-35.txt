import matplotlib.pyplot as plt
from datetime import datetime

def log():
	# read file into string
	with open('rl_template.py', 'r') as inputfile:
		textstr = inputfile.read()
		fn = datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + ".txt"
		
		with open("logs/"+fn, 'w') as outputfile:
			outputfile.write(textstr)

log()


N     = 100  # The goal for truly winning
p     = 0.25 # Probability of winning one bet
gamma = 1    # discount factor

states          = [i for i in range(1, N)]   # The states of the game when defined as a Markov Decision Process.
											 # states[x] represents the state of currently having x chips.
v               = [0 for i in range(0, N+1)] # The current state value function. v[x] is the value of state x.
optimal_actions = [0 for i in range(0, N+1)] # List to represent optimal policy. 
											 # optimal_actions[x] should equal the optimal number of 
											 # coins to bet when you currently have x chips (you're in state x).

											 # For both v and optimal_actions, if x == 0 or N, v[x] = optimal_actions[x] = 0.

### Implement value iteration here ###

def vnext(v1):
	v2=v1[:]
	for x in range(1,N):
		for a in range(1,min(x,100-x)+1):
			v2[x]=max(v2[x],x+(3/4)*v1[x-a]+(1/4)*v1[x+a])
	return v2


def keep(v,a):
	if vnext(v)==v or a ==2:
		return v
	else:
		a+=1
		return keep(vnext(v),a)
		

vk=keep(v,0)
c=0
for x in range(1,N):
		for a in range(1,min(x,100-x)+1):
			c=max(c,x+(3/4)*vk[x-a]+(1/4)*vk[x+a])
			if c==x+(3/4)*vk[x-a]+(1/4)*vk[x+a]:
				optimal_actions[x]=a
		c=0

print(optimal_actions)





######################################
# Plot state value function for every state
fig = plt.figure()
plt.plot(states, vk[1:101])
plt.show()

'''
# Plot optimal policy for every state
plt.plot(states, optimal_actions[1:-1], 'o')
plt.show()
'''